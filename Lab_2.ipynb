{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIJAvPYbGmkx"
      },
      "source": [
        "# **Monitoring pasażerów za pomocą algorytmu SafeSO**\n",
        "\n",
        "W niniejszym ćwiczeniu wykorzystamy podejście zaproponowane w ramach algorytmu SafeSO do monitorignu pasażerów na tylnym siedzeniu pojazdu. Zastosujemy przy tym sieć MobileNetV2 i porównamy jej wyniki na tle innych, przetestowanych przez autorów SafeSO."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTdEkNA10yvQ"
      },
      "source": [
        "# Przygotowanie bazy danych\n",
        "W naszych badaniach użyjemy zbioru SVIRO. Zawiera on sztucznie wygenerowane obrazy tylnych siedzeń różnych pojazdów, które zostały zaklasyfikowane do 7 kategorii:\n",
        "0. puste siedzenie,\n",
        "1. niemowlę w foteliku,\n",
        "2. dziecko w foteliku,\n",
        "3. osoba dorosła,\n",
        "4. rzecz codziennego użytku (np. poduszka, torba),\n",
        "5. pusty fotelik niemowlęcy,\n",
        "6. pusty fotelik dziecięcy.\n",
        "\n",
        "W naszych badaniach, podobnie jak to było w przypadku oryginalnych prac nad algorytmem SafeSO, wykorzystamy kolorowe (RGB) obrazy wnętrzna samochodu BMW x5, z wyciętymi pojedynczymi siedzeniami."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPzFDdGZLsRJ"
      },
      "source": [
        "Zbiór SVIRO jest ogólnie dostępny na dedykowanej mu [stronie internetowej](https://sviro.kl.dfki.de/). Jak już wspomniano, zawiera on ogólnie zdjęcia różnych pojazdów, dodatkowo w kilku wersjach (skala szarości, RGB, głębia). Interesujący nas wariant możemy pobrać i przygotować do wykorzystania za pomocą poniższych komend (proszę się upewnić, czy wszystkie z nich są zrozumiałe!).\n",
        "\n",
        "**Uwaga.** W zależności od łącza internetowego, proces pobierania może potrwać nawet kilka minut."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTU4cU9_1ewt",
        "outputId": "e15629e0-0685-4335-8a58-1b5215b3b43e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-10-18 11:29:21--  https://sviro.kl.dfki.de/download/bmw-x5-4/?wpdmdl=423\n",
            "Resolving sviro.kl.dfki.de (sviro.kl.dfki.de)... 193.175.65.22\n",
            "Connecting to sviro.kl.dfki.de (sviro.kl.dfki.de)|193.175.65.22|:443... failed: Connection timed out.\n",
            "Retrying.\n",
            "\n",
            "--2023-10-18 11:31:31--  (try: 2)  https://sviro.kl.dfki.de/download/bmw-x5-4/?wpdmdl=423\n",
            "Connecting to sviro.kl.dfki.de (sviro.kl.dfki.de)|193.175.65.22|:443... failed: Connection timed out.\n",
            "Retrying.\n",
            "\n",
            "--2023-10-18 11:33:43--  (try: 3)  https://sviro.kl.dfki.de/download/bmw-x5-4/?wpdmdl=423\n",
            "Connecting to sviro.kl.dfki.de (sviro.kl.dfki.de)|193.175.65.22|:443... failed: Connection timed out.\n",
            "Retrying.\n",
            "\n",
            "--2023-10-18 11:35:55--  (try: 4)  https://sviro.kl.dfki.de/download/bmw-x5-4/?wpdmdl=423\n",
            "Connecting to sviro.kl.dfki.de (sviro.kl.dfki.de)|193.175.65.22|:443... failed: Connection timed out.\n",
            "Retrying.\n",
            "\n",
            "--2023-10-18 11:38:11--  (try: 5)  https://sviro.kl.dfki.de/download/bmw-x5-4/?wpdmdl=423\n",
            "Connecting to sviro.kl.dfki.de (sviro.kl.dfki.de)|193.175.65.22|:443... failed: Connection timed out.\n",
            "Retrying.\n",
            "\n",
            "--2023-10-18 11:40:27--  (try: 6)  https://sviro.kl.dfki.de/download/bmw-x5-4/?wpdmdl=423\n",
            "Connecting to sviro.kl.dfki.de (sviro.kl.dfki.de)|193.175.65.22|:443... failed: Connection timed out.\n",
            "Retrying.\n",
            "\n",
            "--2023-10-18 11:42:44--  (try: 7)  https://sviro.kl.dfki.de/download/bmw-x5-4/?wpdmdl=423\n",
            "Connecting to sviro.kl.dfki.de (sviro.kl.dfki.de)|193.175.65.22|:443... failed: Connection timed out.\n",
            "Retrying.\n",
            "\n",
            "--2023-10-18 11:45:00--  (try: 8)  https://sviro.kl.dfki.de/download/bmw-x5-4/?wpdmdl=423\n",
            "Connecting to sviro.kl.dfki.de (sviro.kl.dfki.de)|193.175.65.22|:443... failed: Connection timed out.\n",
            "Retrying.\n",
            "\n",
            "--2023-10-18 11:47:20--  (try: 9)  https://sviro.kl.dfki.de/download/bmw-x5-4/?wpdmdl=423\n",
            "Connecting to sviro.kl.dfki.de (sviro.kl.dfki.de)|193.175.65.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1630593735 (1.5G) [application/zip]\n",
            "Saving to: ‘index.html?wpdmdl=423’\n",
            "\n",
            "index.html?wpdmdl=4  22%[===>                ] 348.00M  4.00MB/s    in 88s     \n",
            "\n",
            "2023-10-18 11:48:49 (3.97 MB/s) - Connection closed at byte 364904448. Retrying.\n",
            "\n",
            "--2023-10-18 11:48:58--  (try:10)  https://sviro.kl.dfki.de/download/bmw-x5-4/?wpdmdl=423\n",
            "Connecting to sviro.kl.dfki.de (sviro.kl.dfki.de)|193.175.65.22|:443... failed: Connection refused.\n",
            "Resolving sviro.kl.dfki.de (sviro.kl.dfki.de)... 193.175.65.22\n",
            "Connecting to sviro.kl.dfki.de (sviro.kl.dfki.de)|193.175.65.22|:443... failed: Connection refused.\n",
            "Archive:  index.html?wpdmdl=423\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of index.html?wpdmdl=423 or\n",
            "        index.html?wpdmdl=423.zip, and cannot find index.html?wpdmdl=423.ZIP, period.\n",
            "\n",
            "No zipfiles found.\n"
          ]
        }
      ],
      "source": [
        "!wget https://sviro.kl.dfki.de/download/bmw-x5-4/?wpdmdl=423\n",
        "!unzip index.html?wpdmdl=423\n",
        "!rm index.html?wpdmdl=423"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRG7GxO90WtW"
      },
      "source": [
        "Teraz przystępujemy do realizacji właściwego zadania - najpierw importujemy wszystkie potrzebne pakiety:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzf4Bjx5yz1m"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.models as models\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import copy\n",
        "import numpy as np\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-r17Ml65853"
      },
      "source": [
        "Ustawiamy ścieżki do odpowiednich zbiorów (uczącego i testowego):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8oEkO3p6Jvi"
      },
      "outputs": [],
      "source": [
        "SVIRO_train_path =  # FIXME - np. ścieżka: './x5/train/RGB'\n",
        "SVIRO_test_path = # FIXME - np. ścieżka: './x5/test_with_labels/RGB'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiDQDWAL6Tw_"
      },
      "source": [
        "Jak już wspomniano, w dalszej części ćwiczenia będziemy wykorzystywali sieć MobileNetV2. Na wejściu pierwszej warstwy wymaga ona tensorów w rozmiarze [3 x 224 x 224]. O ile pierwszy z wymienionych wymiarów jest zapewniony poprzez wykorzystanie obrazów RGB, o tyle pozostałe dwa musimy uzyskać za pomocą odpowiednich transformacji (oryginalne obrazy są bowiem prostokątami). Zastosujemy przy tym często spotykane podejście: najpierw przeskalujemy obraz w ten sposób, że krótszy bok będzie miał długość zbliżoną do docelowej (przyjmijmy 256), a następnie wytniemy z niego kwadrat o pożądanych rozmiarach.\n",
        "\n",
        "**Zadanie.** Proszę uzupełnić zestaw przekształceń preprocessingu, wykorzystując moduł transforms z pakietu torchvision i metody: Resize, CenterCrop oraz ToTensor. Oczywiście kolejność przekształceń ma znaczenie. W razie wątpliwości można skorzystać z [dokumentacji modułu transforms](https://pytorch.org/vision/stable/transforms.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-tt0aD96Yck"
      },
      "outputs": [],
      "source": [
        "preprocessing = transforms.Compose([]) # TODO - uzupełnić tablicę []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLxvdod66aDp"
      },
      "source": [
        "Pakiet torchvision udostępnia wygodne API do pobierania wielu popularnych zbiorów danych. Niestety, do tego grona nie zalicza się SVIRO. Możemy jednak wykorzystać ogólną klasę ImageFolder do obsłużenia naszego zbioru.\n",
        "\n",
        "**Zadanie.** Po zapoznaniu się z [dokumentacją ImageFolder](https://pytorch.org/vision/stable/datasets.html#torchvision.datasets.ImageFolder) proszę wykorzystać tę klasę do obsłużenia uczącego i testowego zbioru SVIRO. W obu przypadkach wystarczą dwa argumenty: ścieżka i zestaw transformacji (taki sam dla obu zbiorów)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7byAdDe6j4U"
      },
      "outputs": [],
      "source": [
        "SVIRO_train = # TODO - zbiór uczący\n",
        "SVIRO_test = # TODO - zbiór testowy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFMh9nGsd7mL"
      },
      "source": [
        "Oprócz dwóch wspomnianych zbiorów, będziemy również potrzebowali zbioru walidacyjnego do kontrolowania procesu uczenia. Możemy go utworzyć poprzez losowy podział oryginalnego zbioru uczącego, np. 10% przeznaczyć na zbiór walidacyjny, a pozostałą część na właściwy zbiór uczący. Do tego celu służy metoda [SubsetRandomSampler](https://pytorch.org/docs/stable/data.html#torch.utils.data.SubsetRandomSampler), z której skorzystamy w naszym przypadku, a następnie wświetlimy finalną liczbę obrazów w każdym zbiorze:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_L31f8Q6zEs"
      },
      "outputs": [],
      "source": [
        "val_split = 0.1\n",
        "SVIRO_train_size = len(SVIRO_train)\n",
        "split = int(np.floor(val_split * SVIRO_train_size))\n",
        "\n",
        "indices = list(range(SVIRO_train_size))\n",
        "np.random.seed(13)\n",
        "np.random.shuffle(indices)\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "val_sampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "dataset_sizes = {'train': len(train_indices), 'val': len(val_indices), 'test': SVIRO_test.__len__()}\n",
        "\n",
        "for x in ['train', 'val', 'test']:\n",
        "    print('[INFO] Number of ' + x + ' samples: ' + str(dataset_sizes[x]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqw20d5b63V4"
      },
      "source": [
        "Oprócz pobierania zawartości danego zbioru (czy to z internetu, czy z dysku lokalnego), PyTorch umożliwia również wygodne wczytywanie poszczególnych obrazów za pomocą klasy DataLoader.\n",
        "\n",
        "**Zadanie.** Po zapoznaniu się z [dokumentacją DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) proszę przygotować loadery dla każdego z trzech zbiorów: uczącego, walidacyjnego i testowego. We wszystkich przypadkach będziemy potrzebowali trzech argumentów: źródła danych (*dataset*) - SVIRO_train lub SVIRO_test, rozmiaru batcha (*batch_size*) - wszędzie jednakowy oraz *pin_memory* z wartością True. Ostatni argument umożliwia przyspieszenie wczytywania danych do GPU z wykorzystaniem CUDA. W przypadku loaderów zbioru uczącego i walidacyjnego musimy również wykorzystać argument *sampler* z przygotowanymi wcześniej obiektami klasy SubsetRandomSampler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpumUxVA7AbY"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "train_loader = # TODO - loader dla zbioru uczącego\n",
        "val_loader = # TODO - loader dla zbioru walidacyjnego\n",
        "test_loader = # TODO - loader dla zbioru testowego\n",
        "\n",
        "dataloaders = {'train': train_loader, 'val': val_loader, 'test': test_loader}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3YP-aZn7FVH"
      },
      "source": [
        "Naszą docelową platformę wykonywania obliczeń stanowi GPU z CUDA (o ile tylko jest dostępne), co możemy wyrazić przez instrukcję warunkową przedstawioną poniżej.\n",
        "\n",
        "**Uwaga.** Proszę dobrze zapamiętać poniższą instrukcję, gdyż będzie ona nam wielokrotnie potrzebna."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzJp0vzS7HYg"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrfDhLdinHkz"
      },
      "source": [
        "# Funkcja ucząca i model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP4OGPVC7Lg5"
      },
      "source": [
        "Będziemy przeprowadzać dwukrotne uczenie sieci neuronowej, stąd warto zdefiniować odrębną funkcję uczącą.\n",
        "\n",
        "**Zadanie.** Zdefiniować funkcję uczącą na podstawie [poradnika o Transfer Learningu w Pytorchu](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html#training-the-model)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiSR3SLc7RbF"
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    # TODO\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1rg1VsP7TIi"
      },
      "source": [
        "Pakiet torchvision udostępnia szereg modeli sieci neuronowych wytrenowanych na zbiorze ImageNet. Wśród nich znajduje się również model sieci MobileNetV2, który wczytujemy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egvvrIKy7WsO"
      },
      "outputs": [],
      "source": [
        "model = models.mobilenet_v2(pretrained=True)\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wBl_DPm7Yta"
      },
      "source": [
        "# Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zs_pPiC1snUh"
      },
      "source": [
        "Wczytana przez nas sieć jest przystosowana do klasyfikacji obiektów (zwierząt) pochodzących z 1000 klas. Jak już wspomniano, w zbiorze SVIRO mamy jedynie 7 klas. Wobec tego musimy zmienić klasyfikator oraz przystosować całą sieć do nowego zbioru danych. Wzorując się na algorytmie SafeSO, dokonamy tego w dwóch etapach: najpierw nauczymy sam klasyfikator na podstawie cech wykrywanych przez oryginalną sieć, a następnie dokonany finetuningu całości. Przy wykonywaniu tych kroków można wzorować się na wspomnianym już [poradniku o Transfer Learningu w PyTorchu](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqIgQ9G4dyvX"
      },
      "source": [
        "## Uczenie klasyfikatora"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJWLaw9J7f4L"
      },
      "source": [
        "W pierwszym etapie musimy przede wszystkim zmienić klasyfikator sieci i przeprowadzić jego uczenie. Zgodnie z przyjętą metodologią, potrzebujemy równocześnie \"zamrozić\" parametry warstw odpowiedzialnych za ekstrakcję cech. Najprościej zrealizować to w następującej kolejności:\n",
        "1. Zamrozić **wszystkie** parametry oryginalnej sieci (doprowadzi to również do zamrożenia parametrów oryginalnego klasyfikatora, ale zaraz go i tak wymienimy, więc nie ma to dla nas znaczenia).\n",
        "2. Wymienić klasyfikator na właściwy dla naszego problemu.\n",
        "3. Przeprowadzić uczenie tak przygotowanej sieci."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcfQhHEEUgLt"
      },
      "source": [
        "**Zadanie.** Proszę zamrozić parametry oryginalnej sieci za pomocą odpowiedniego ustawienia flagi *requires_grad*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrvgK6Qd7lz2"
      },
      "outputs": [],
      "source": [
        "for param in model.parameters():\n",
        "    # TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYB3WAiP7n9j"
      },
      "source": [
        "**Zadanie.** Proszę zdefiniować nowy klasyfikator dla naszej sieci. Ma on mieć taką samą strukturę i parametry, jak oryginalny klasyfikator (por. rezultat wywołania *print(model)* powyżej), tylko zamiast 1000 cech wyjściowych (*out_features*) powinien mieć ich 7 (tyle, ile klas w zbiorze danych). Należy skorzystać z warstw *nn.Dropout* oraz *nn.Linear*, a do ich połączenia można użyć kontenera *nn.Sequential*. Informacje o nich znajdują się w dokumentacji [torch.nn](https://pytorch.org/docs/stable/nn.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rNBvVRWi73uv"
      },
      "outputs": [],
      "source": [
        "new_cls = # TODO\n",
        "model.classifier = new_cls\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdBnW_gU77h1"
      },
      "source": [
        "Gotowy model umieszczamy w pamięci urządzenia, na którym pracujemy (np. GPU z CUDA):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LILAj2ne8BCC"
      },
      "outputs": [],
      "source": [
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdPbDnM48IPi"
      },
      "source": [
        "Możemy teraz przystąpić do uczenia naszego modelu. W tym celu musimy najpierw zdefiniować funkcję błędu, optymalizator i scheduler. Co istotne, w pierwszym etapie chcemy uczyć jedynie parametry klasyfikatora naszego modelu (można je znaleźć poprzez wywołanie *model.classifier.parameters()*), więc to na nich powinien działać optymalizator.\n",
        "\n",
        "**Zadanie.** Proszę zdefiniować *CrossEntropyLoss* jako funkcję błędu, optymalizator *Adam* (ze współczynnikiem uczenia *lr=1e-2*) oraz scheduler *StepLR* (współczynnik *gamma=0.1*, *step_size* można natomiast testować różny, a na początek przyjąć 3). Należy pamiętać o przekazaniu właściwych parametrów sieci do optymalizatora. W razie wątpliwości można wesprzeć się dokumentacją\n",
        "modułów [torch.nn](https://pytorch.org/docs/stable/nn.html) i [torch.optim](https://pytorch.org/docs/stable/optim.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LP7hTkdf8RHA"
      },
      "outputs": [],
      "source": [
        "criterion = # TODO - funkcja błędu\n",
        "optimizer_cls = # TODO - optymalizator\n",
        "scheduler_cls = # TODO - scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8BxStM_a-zF"
      },
      "source": [
        "Przeprowadzamy uczenie naszego modelu, wykorzystując zdefiniowaną uprzednio funkcję *train_model*.\n",
        "\n",
        "**Uwaga.** Może to potrwać kilka minut."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8MS-Vw5a7SY"
      },
      "outputs": [],
      "source": [
        "model = train_model(model=model, criterion=criterion, optimizer=optimizer_cls, scheduler=scheduler_cls, num_epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Rz9yi5v8crc"
      },
      "source": [
        "Podobnie, jak uczenie, tak i ewaluację będziemy przeprowadzać dwukrotnie. W związku z tym warto przygotować sobie ogólną funkcję do tego celu.\n",
        "\n",
        "**Zadanie.** Proszę zapoznać się z poniższą funkcją ewaluacyjną (np. czekając, aż sieć się nauczy). Szczególną uwagę należy zwrócić na instrukcje związane z obsługą gradientów oraz sposób konwersji wyników z PyTorcha do Numpy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8K4551X8gTK"
      },
      "outputs": [],
      "source": [
        "def test_model(model):\n",
        "    predictions = np.array([])\n",
        "    true_values = np.array([])\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for inputs, labels in dataloaders['test']:\n",
        "        inputs = inputs.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        predictions = np.append(predictions, preds.detach().cpu().numpy())\n",
        "        true_values = np.append(true_values, labels.data.numpy())\n",
        "\n",
        "    return true_values, predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Fs2--JR8iE0"
      },
      "source": [
        "Na koniec tego etapu przeprowadzamy ewaluację uzyskanych wyników. Posłużymy się przy tym macierzą błędów (ang. *confusion matrix*) oraz wynikającymi z niej parametrami, obliczonymi za pomocą modułu *metrics* z pakietu *scikit-learn*.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NA_3sNg8vnb"
      },
      "outputs": [],
      "source": [
        "true_values, predictions = test_model(model)\n",
        "\n",
        "print(metrics.classification_report(true_values, predictions, digits=3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5u83Ssa87by"
      },
      "source": [
        "## Finetuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQoBMHfveIgX"
      },
      "source": [
        "Po wstępnym nauczeniu klasyfikatora, przechodzimy do drugiego etapu. Teraz traktujemy sieć jako całość zainicjalizowaną pretrenowanymi parametrami:\n",
        "- warstwy odpowiedzialne za ekstrakcję cech mają wagi nauczone na zbiorze zwierząt,\n",
        "- klasyfikator ma wagi wyuczone przed chwilą przez nas.\n",
        "\n",
        "Tym razem sprawa jest prostsza: wystarczy odmrozić wszystkie wagi i można przystąpić do uczenia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5_BJC6L891h"
      },
      "source": [
        "**Zadanie.** Proszę odmrozić uczenie wszystkich parametrów modelu poprzez odpowiednie ustawienie flagi *requires_grad*:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0iN1pJi9Fki"
      },
      "outputs": [],
      "source": [
        "for param in model.parameters():\n",
        "    # TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3WOLwQo9JJl"
      },
      "source": [
        "**Zadanie.** Proszę zdefiniować nowy optymalizator (ponownie *Adam*, tylko z dostępem do **wszystkich** parametrów modelu oraz ze współczynnikiem uczenia *lr=1e-4*) oraz nowy scheduler (taki, jak poprzednio)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMSad42V9NCx"
      },
      "outputs": [],
      "source": [
        "optimizer_ft = # TODO - optymalizator\n",
        "scheduler_ft = # TODO - scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrrSaFffgPd7"
      },
      "source": [
        "Uczymy sieć.\n",
        "\n",
        "**Uwaga.** Chwila wytchnienia, chwilę to potrwa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6-J8JlggcE0"
      },
      "outputs": [],
      "source": [
        "model = train_model(model=model, criterion=criterion, optimizer=optimizer_ft, scheduler=scheduler_ft, num_epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-8-5KYZ9VOC"
      },
      "source": [
        "Ponownie weryfikujemy rezultat uczenia na zbiorze testowym z wykorzystaniem tych samych metryk:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-SVLMrN9ZCE"
      },
      "outputs": [],
      "source": [
        "true_values, predictions = test_model(model)\n",
        "\n",
        "print(metrics.classification_report(true_values, predictions, digits=3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEZuJE4rha_Y"
      },
      "source": [
        "# Pytania kontrolne\n",
        "\n",
        "W celu podsumowania wykonanych ćwiczeń proszę odpowiedź na poniższe pytania kontrolne:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU_a5weuhxB6"
      },
      "source": [
        "1. Czy finetuning poprawił uzyskiwane rezultaty? Odpowiedź **uzasadnij**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFT65-YkiB9w"
      },
      "source": [
        "**Odpowiedź:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa4shJtViKg8"
      },
      "source": [
        "2. Jak uzyskane wyniki plasują się na tle rezultatów uzyskanych przez autorów algorytmów SafeSO dla różnych testowanych przez nich sieci?\n",
        "Przeanalizuj złożoność (liczba warst, liczba parametrów) sieci MobilNet oraz tej wykorzystanej w artykurze SafeSO i porównaj.\n",
        "Weź pod uwagę liczbę parametrów oraz dokładność inferencji i rozważ przynajmniej dwie sytuacje, w których mniejsza sieć ma przewagę nad dużo większymi siecią."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpHmi4nOiau7"
      },
      "source": [
        "**Odpowiedź:**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}